{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc\n",
    "from string import punctuation\n",
    "import re\n",
    "import numpy as np\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression, NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = ps.SparkContext(\"local\", \"Simple App\")\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession(sc)\n",
    "train_path='data.csv'\n",
    "train_rdd = sc.textFile(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tolower(lines):\n",
    "    lines = lines.lower()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_numbers(s):\n",
    "    s = re.sub('^[0-9]+', '', s)\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_rdd = train_rdd.map(tolower).map(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_punctuation(s):\n",
    "    return ''.join(c for c in s if c not in punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseTrain(rdd):\n",
    " \n",
    "    header = rdd.first()\n",
    "    print(header)\n",
    "    body = rdd.filter(lambda r: r!=header)\n",
    "    def parseRow(row):\n",
    "        print(row)\n",
    "        for i in\n",
    "        stopwords = [\"like\", \"just\", \"will\", \"&amp\",\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"arent't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\",\"between\",\"both\",\"but\",\"by\",\"can\", \"can't\", \"cannot\",\"could\",\"couldn't\",\"did\",\"didn't\",\"do\",\"does\",\"doesn't\",\"doing\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"hadn't\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\", \"hes\", \"her's\" ,\"her\",\"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"ive\",\"if\",\"in\",\"into\",\"is\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"let's\",\"me\",\"more\",\"most\",\"mustn't\",\"my\",\"myself\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"shan't\",\"she\",\"she'd\",\"she'll\",\"she's\",\"should\",\"shouldn't\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"there's\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"wasn't\",\"we\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"were\",\"weren't\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\"won't\",\"would\",\"wouldn't\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\"]\n",
    "        new_rowlist = [0,0]\n",
    "        new_rowlist[0] = row_list[0]\n",
    "        new_rowlist[1] = \" \".join(row_list[1:])\n",
    "        \tnew_rowlist[1] = new_rowlist[1].replace(i, \" \")\n",
    "        new_rowlist[1] = strip_punctuation(str(new_rowlist[1]))\n",
    "        new_rowlist[1] = re.sub(\"\\s\\s+\" , \" \", str(new_rowlist[1]))\n",
    "        return row_tuple\n",
    " \n",
    "    rdd_parsed = body.map(parseRow)\n",
    " \n",
    "    colnames = header.split(\",\")\n",
    " \n",
    "    return rdd_parsed.toDF(colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar,text\n"
     ]
    }
   ],
   "source": [
    "df = parseTrain(train_rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashtf = HashingTF(numFeatures=2**10, inputCol=\"words\", outputCol='features')\n",
    "label_stringIdx = StringIndexer(inputCol = \"text\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[tokenizer, hashtf, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(df)\n",
    "train_df = pipelineFit.transform(df)\n",
    "(train_set, test_set, final_testset) = train_df.randomSplit([0.8, 0.1, 0.1], seed = 1235)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=100)\n",
    "lrModel = lr.fit(train_set)\n",
    "predictions = lrModel.transform(train_set)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "train_logistic = evaluator.evaluate(predictions)\n",
    "predictions = lrModel.transform(test_set)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "test_logistic = evaluator.evaluate(predictions)\n",
    "predictions = lrModel.transform(finalset)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "finaltest_logistic = evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes(smoothing=1e-9)\n",
    "nbModel = nb.fit(train_set)\n",
    "pred = nbModel.transform(train_set)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "train_nb = evaluator.evaluate(pred)\n",
    "pred = nbModel.transform(test_set)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "test_nb = evaluator.evaluate(pred)\n",
    "pred = nbModel.transform(final_testset)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "finaltest_nb = evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees = 150, maxDepth = 7)\n",
    "rfModel = rf.fit(train_set)\n",
    "pred = rfModel.transform(train_set)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "train_rf = evaluator.evaluate(pred)\n",
    "pred = rfModel.transform(test_set)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "test_rf = evaluator.evaluate(pred)\n",
    "pred = rfModel.transform(final_testset)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "finaltest_rf = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lrModel.transform(final_testset)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "finaltest_logistic = evaluator.evaluate(predictions)\n",
    "\n",
    "predictions = model.transform(final_testset)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "finaltest_nb = evaluator.evaluate(predictions)\n",
    "\n",
    "predictions = rfModel.transform(final_testset)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "finaltest_rf = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Accuracy:\n",
      "\n",
      "Logistic Regression:\n",
      " 0.6434101018999994\n",
      "Random Forest:\n",
      " 0.5271271381803007\n",
      "Naive Bayes:\n",
      " 0.4739655196936644\n",
      "\n",
      " Test Accuracy:\n",
      "Logistic Regression Accuracy:\n",
      " 0.6768135639639883\n",
      "Random Forest Accuracy:\n",
      " 0.45711989989833335\n",
      "Naive Bayes Accuracy:\n",
      " 0.4547989126898396\n",
      "\n",
      " Final Accuracy Results:\n",
      "\n",
      "Logistic Regression Acc:\n",
      " 0.67882345545\n",
      "Random Forest Accuracy:\n",
      " 0.49066176809333334\n",
      "Naive Bayes Accuracy:\n",
      " 0.47848484871\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Train Accuracy:\\n\")\n",
    "print(\"Logistic Regression:\\n\", train_logistic)\n",
    "print(\"Random Forest:\\n\", train_rf)\n",
    "print(\"Naive Bayes:\\n\", train_nb)\n",
    "print(\"\\n Test Accuracy:\")\n",
    "print(\"Logistic Regression Accuracy:\\n\", test_logistic)\n",
    "print(\"Random Forest Accuracy:\\n\", test_rf)\n",
    "print(\"Naive Bayes Accuracy:\\n\", test_nb)\n",
    "\n",
    "print(\"\\n Final Accuracy Results:\\n\")\n",
    "print(\"Logistic Regression Acc:\\n\", finaltest_logistic)\n",
    "print(\"Random Forest Accuracy:\\n\", finaltest_rf)\n",
    "print(\"Naive Bayes Accuracy:\\n\", finaltest_nb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
